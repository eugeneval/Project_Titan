\documentclass[10pt]{article}
\usepackage{textcomp}
\usepackage{longtable}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{color}
\usepackage[hyphens]{url}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}

\graphicspath{ {Images/}{Graphs/} }
\author{Eugene Valetsky\\ \and Supervisor: Dr Tim Baker}
\title{Unmanned Aerial Systems}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DOCUMENT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\maketitle

\section{Introduction}
\subsection{Background}
The Unmanned Aerial System (UAS) Challenge was launched by the Institution of Mechanical Engineers (IMechE) in 2014 `with the key objectives of developing professional engineers and inspiring the next generation'\cite{IMechE_about_uas}. The main goal is to design and build a UAS in order to autonomously deliver humanitarian aid such as medical supplies in a disaster zone. This requires a broad range of skills, from project management to airframe design to avionics system programming. To add to the challenge there is a strict weight limit and stringent safety regulations. Working together with another student, Ismail Ahmad, our goal is to follow the design and build cycle all the way through to competing at the IMechE UAS competition in July 2018.

\subsection{Problem Definition}
One of the greatest individual challenges as part of the project is creating an autonomous flight system. The UAS must be capable of quickly and safely navigating to and locating a target using computer vision, dropping a payload accurately, and returning to base. This requires an understanding of the UASâ€™s flight dynamics as well as good programming and wiring capabilities. This is the aspect that I will be focusing on for my individual project, although I will be assisting with many parts of the project.

\subsection{Design Concept}
The concept for our UAS uses a hybrid symbioisis between a \emph{Micro Jet Engine}, henceforth refered to as MJE, and an external multi-rotor. The MJE is gimballed to always remain vertical and only provides lift, while the multirotor rotates around it providing stabilisation and control. This configuration means that standard quadcopter flight control software can be used rather than needing to come up with custom architecture.

The MJE provides a higher thrust to weight ratio than the equivalent electric motors and batteries. It does this without introducing the vibration issues of a piston engine, which would seriously impact stability and control on such a lightweight design. With the current MJE and electric motors we hope to lift a payload of 3kg while remaining under the 6.9kg weight limit.

Flight control will be handled with a Pixhawk running the PX4 flight stack. This will be coupled to a companion computer running software based on the DroneKit SDK, communicating with the PixHawk using the MAVLink protocol. The companion computer is responsible for communication, waypoint navigation, and target location and tracking using computer vision. It then communicates where to go to the PixHawk.

\section{System Plausibility}
One of the main concepts behind the UAS concept is the idea that, if the MJE is gimballed to remain vertical, and its thrust vector is through the center of gravity of the vehicle, it exerts no horizontal forces or moments on the rest of the vehicle. This means its effect on the stability and control of the vehicle can be ignored. In turn, this means that regular quadcopter flight control software can be used, such as the PX4 flight stack.

Being able to use PX4 firmware running on a Pixhawk is crucial. The UAS will come to cost approximately \pounds2,500. Using home-made flight control software is therefore extremely risky. PX4, on the other hand, is a project that has been worked on by thousands of people for years, and is infinitely more reliable than anything we could put together from scratch.

Therefore, it was decided to build a simulation to test the validity of the concept that the MJE can be ignored.

\subsection{Design Requirements}
\subsection{Design Methodology}
\begin{enumerate}
    \item Create a simplified model of the vehicle.
    \item Determine equations of motion for this model.
    \item Creating PID controllers.
    \item Create a simulation based on these equations of motion and PID controllers.
    \item Test the validity of the core concept.
\end{enumerate}

\subsection{Progress}
\subsubsection{Equations of Motion}
The vehicle is split into two sections, the outer quadcopter frame, \emph{Quad}, and the gimballed section containing the MJE, \emph{Jet}.

The quad is modeled as an inner thin, hollow cylinder, the \emph{frame}, with four cyclindrical rods, the \emph{arms}, extending outwards. The motors are point masses on the ends of the arms. It is assumed to be constructed of aircraft-grade aluminium. The jet is modelled as a cylinder.

The gimbal is controlled by two servos, one moving the gimbal in roll and one in pitch. (There is no need for yaw control of the jet.) The multirotor uses the 'quad-x' configuration.

From these initial assumptions, equations of motion were determined. These consist of:
\begin{enumerate}
    \item The total mass of the vehicle.
    \item Sum of forces on the vehicle in x, y, and z directions.
    \item Inertia of the quad.
    \item Sum of torques on the quad.
    \item Inertia of the jet.
\end{enumerate}

\subsubsection{PID Control}
8 PID controllers are needed in total: 3 position and 3 angle controllers for the quad, and 2 angle controllers for the jet gimbal. These controllers use the standard PID control logic:
\begin{eqnarray*}
    error = setpoint - actual\ value \\
    integral = integral + (error \times time\ period) \\
    derivative = (error - previous\ error)/time \\
    output = kP \times error + kI \times integral + kD \times derivative
\end{eqnarray*}
where kP, kI, and kD are constants to be optimised.

In a real quadcopter, the controller sends a signal to an \emph{electronic speed control} (ESC), which in turn sends a \emph{pulse width modulation} (PWM) signal to the motor, controlling its speed. In this model this has been simplified, such that the controller output directly controls the force exerted by the motors. The servo controller output determines the torque exerted by the servo.

The controllers work in sequence, with the x and y position controllers determing the setpoint of the x and y angle controllers. The Z axis controllers are independent, as are the servo controllers.

\subsubsection{Programming}
The simulation itself was written in Processing. This is a language originally based on Java that is designed for ease of programming, especially with regards to displaying graphical elements. It was chosen over using MATLAB due to the author's increased familiarity with it, and the fact that this simulation has no need of advanced mathematical capability - there are no complex differential equations or matrix operations.

The program was built up in stages, with the physics of each stage checked before adding complexity. As far as possible, good object-oriented programming practice has been followed.

The quad section was implemented first. A controller was first tested solely in the z direction, and the response was used to calibrate PID values for the z controller. Angular controllers were then implemented, tested, and calibrated, before finally introducing x and y position controllers.

Testing involved flying a simple path: takeoff to 10m, a square path (10m north, 10m east, 10m south, 10m west), and then landing. This gave the results seen in Figure \ref{fig:square_path_quad_only}. It can be seen that there is an oscilliation in x and y position. It proved difficult to eliminate, due to the not straightforward interaction of position and angle PID values. This, however proved not to be a problem. It can be seen in Figure \ref{fig:square_path_w_jet} that the addition of the jet has, likely due to the added mass, damped out the oscillations in x and y position. It has also added an overshoot in z and a steady state error in x and y, but this can be corrected by fine-tuning of PID values. The flight time has also increased but this is to be expected with greater mass. In Figure \ref{fig:square_path_w_jet_angle} we can see how the quadcopter changes angle about the x axis, and how the jet initially starts to move in that direction but is quickly brought back to the vertical by the servo.

\begin{figure}[p]
    \centering
    \begin{subfigure}{0.72\textwidth}
        \includegraphics[width=\textwidth]{square_path_quad_only}
        \caption{Square Path - Quad Only}
        \label{fig:square_path_quad_only}
    \end{subfigure}

    \begin{subfigure}{0.72\textwidth}
        \includegraphics[width=\textwidth]{square_path_w_jet}
        \caption{Square Path - With Jet}
        \label{fig:square_path_w_jet}
    \end{subfigure}

    \begin{subfigure}{0.72\textwidth}
        \includegraphics[width=\textwidth]{square_path_w_jet_angle}
        \caption{Square Path - With Jet}
        \label{fig:square_path_w_jet_angle}
    \end{subfigure}
    \caption{}
\end{figure}

\subsection{Refiment}
It was realised that the mass of the quad had been implemented incorrectly. Additionally, the maximum torque of the servo had not been limited.

These refiments decreased the stability of the drone. It is still well within acceptable parameters for rotation, and for x and y positioning, but height now has considerable steady state error and oscillation.
% TODO height fucked up graphs

With sufficient PID tuning, height could be stabilised, but not without a massive initial overshoot, and slightly increasing instability in x and y. This is because as the proportion of motor control that comes from height control increases (due to increasing $k_p$ and $k_i$ terms), the proportion of motor control left available for the other controllers decreases.

\subsection{Conclusions and Further Work}
It appears that the addition of a gimballed jet to a quadcopter does not destabilise it. The extremely simple PID controllers used in our simulation are able to cope, implying that a significantly more advanced flight stack such as the PX4 should have no problems. Our initial assumption that the jet can simply be ignored appears valid. Further refiments to the simulation could be made in two ways:

Firstly, the accuracy of the simulation itself could be increased. Many assumptions and simplifications have been made throughout, from assuming the controllers have access to perfect angle and position information, to ignoring the effects of friction and stiction in the gimbal. This would increase the validity of our conclusion.

Secondly, the PID controllers could be improved. It is suspected that the massive overshoot in height could be solved through the introduction of a `limited integral' controller, that only uses the integral term when it is close to the setpoint. More research into the PX4 source code is required to determine what control algorithms it uses and to possibly implement them, increasing the similarity of our simulation's response to how a real PixHawk would respond.

\section{Control Software}
We will be controlling the PixHawk flight controller using offboard commands from an external companion computer, henceforth refered to as Pete (since CC is a rather ambigous acronym). Pete will consist of three main components: communication with the PixHawk, communication with a ground station, and target-finding computer vision.

PX4 is fully capable of Software-in-the-Loop (SITL) simulation, using either the jMAVSim or Gazebo enviroments. This is crucial, as it allows code to be tested with no danger to the real vehicle. Pete can commicate with the simulated vehicle using MAVLink through a UDP port; this is exactly the same as how it would connect to a real vehicle. As far as Pete's code is concerned, there is no difference between a real and a simulated vehicle except for the UDP address.
\subsection{Design Requirements}
\subsection{Design Methodology}
\begin{enumerate}
    \item Research and download required libraries.
    \item Succesfully run a SITL PX4 simulation.
    \item Create a program that can communicate with PX4 over MAVLink.
    \item Use this program to send commands to and control PX4.
    \item Integrate this program with the computer vision and communication on Pete.
\end{enumerate}
\subsection{Progress}
Communication with the PX4 flight stack on the PixHawk is based on the DroneKit SDK. This is a platform for devoloping apps written in Python that run on a drone's companion computer. It communicates with the PixHawk using the MAVLink communication protocol.\cite{dronekit} The DroneCore API was also experimented with but proved significantly harder to implement and hence was abandoned.

PX4 has 12 flight modes when employed on a multirotor. We are interested in the autonomous modes, which include Hold, Return(RTL), Takeoff, Land, Mission, Follow Me, and Offboard. Of particular interest are Mission, in which `the vehicle follows a programmed mission', and Offboard, where `the vehicle obeys a position, velocity or attitude setpoint provided over MAVLink'.\cite{PX4_user_guide}

The available documentation and examples for DroneKit mostly make use of the \lstinline[language=Python]|simple_goto()| command. Unfortunately, as DroneKit is primarily designed to work with APM, the predecessor of PX4, this command does not work. Neither does \lstinline[language=Python]|arm_and_takeoff()|, or the \lstinline|vehicle.groundspeed| and \lstinline|vehicle.airspeed| attributes, among others.

Additionally, it is usually assumed that one is operating in the \lstinline|global_relative_frame|. There are three frames of reference availible:
\begin{center}
\begin{tabular}{cc}
    \lstinline|global_frame| & GPS coordinates, with 0 altitude at sea level \\
    \lstinline|global_relative_frame| & GPS coordinates, with 0 altidue as ground level at the starting location \\
    \lstinline|local_frame| & Cartesian coordinates relative to the starting location
\end{tabular}
\end{center}
\lstinline|local_frame| is the most immediately useful to us, as it is simpler and more intuitive to use. Note that this is the North East Down (NED) frame, i.e. -10m altitude is 10m above the ground.

Custom code has had to be written to take the place of these defunct commands and allow the vehicle to be controlled in the desired manner. First of all, we want to be able to directly send a position waypoint to PX4. This is a feature that is not fully implemented in DroneKit, and so a custom command with a custom MAVLink message has been created:
\begin{lstlisting}[language=Python]
def send_ned_position(pos_x, pos_y, pos_z):
    """
    Move vehicle in direction based on specified velocity vectors.
    """

    msg = vehicle.message_factory.set_position_target_local_ned_encode(
        0,       # time_boot_ms (not used)
        0, 0,    # target system, target component
        mavutil.mavlink.MAV_FRAME_LOCAL_NED, # frame
        0b0000111111111000, # type_mask
        pos_x, pos_y, pos_z, # x, y, z positions
        0, 0, 0, # x, y, z velocity in m/s
        0, 0, 0, # x, y, z acceleration (not supported yet)
        0, 0)    # yaw, yaw_rate (not supported yet)

    vehicle.send_mavlink(msg)
\end{lstlisting}

Similarly, other commands have been created to suit our purposes. Some of these have been adapted from examples in the DroneKit and PX4 documentation.\cite{dronekit}\cite{PX4_dev_guide}

\lstinline|arm_and_takeoff()| replaces the command provided in DroneKit, and performs the same function. \lstinline|goto_absolute()| and \lstinline|goto_relative()| allow us to navigate to a position waypoint, simply defined as X meters north, Y meters east, and Z meters up from either the starting location or the current location. The \lstinline|accuracy| attribute optionally allows us to change how close the vehicle must get to the waypoint to consider it to have reached it. \lstinline|setMaxXYSpeed()| is a replacement for the \lstinline|vehicle.groundspeed| attribute present in DroneKit, which does not work as intended with PX4, and allows us to set a maximum groundspeed for the vehicle. Finally, \lstinline|returnToLand()| has the vehicle return to it's starting location and land safely.

\subsection{Conclusions and Further Work}
Altogether, this means that the communication with the PixHawk has been simplified down to a few basic commands. An example mission could consist of the following: arming and taking off, following a series of GPS coordinates, locating a target using computer vision, calculating it's offset from directly underneath the drone, using \lstinline|goto_relative()| to position itself precisely over the target, droping the payload, and returning to base and landing.

There is little further work to be done on this aspect of the project, other than integration with other software components as and when they are completed.

\section{Computer Vision}
The last component of the control system is a comouter vision system capable of identifying the target. This takes the form of a red 1x1m square, incoporating an alphanumeric code in white, within a larger 2x2m white square\cite{IMechE_rules}. The system would have to locate the target, calculate the offset from being centered underneath the vehicle, and to indentify the alphanumeric code.

Since an interface had already been programmed in Python, it was decided to program the computer vision in Python as well to allow for them to easily work in conjucntion. To this end the OpenCV-Python library was chosen.
\subsection{Design Requirements}
\subsection{Design Methodology}
\begin{enumerate}
    \item Research computer vision and download required libraries.
    \item Create a program that can recognise squares.
    \item Create a program that can recognise characters.
    \item Finalise this into a program that can recognise the target and provide useful information.
    \item Integrate this program with PX4 control and communication on Pete.
\end{enumerate}
\subsection{Progress}
A program was created that can recognise squares. This is done by detecting edges in the image, simplifying those edges to contours (a series of points), and seeing which of those contours fit our defintion of a square.

The program can also do Optical Character Recognition (OCR), using the Tesseract engine and pytesseract library.

\begin{lstlisting}[language=Python]
def squares(img):
    # Edge detection
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = cv2.GaussianBlur(img, (5, 5), 0)
    img = cv2.Canny(img, 50, 150)

    # Find contours
    contImg, contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    squares = []
    for c in contours:
        contour_length = cv2.arcLength(c, True)
        approx = cv2.approxPolyDP(c, 0.02 * contour_length, True)

        if 4 <= len(approx) <= 6:
            (x, y, w, h) = cv2.boundingRect(approx)
            aspectRatio = w / float(h)

            area = cv2.contourArea(c)
            hullArea = cv2.contourArea(cv2.convexHull(c))
            solidity = area / float(hullArea)

            checkDimensions = w > 25 and h > 25
            checkSolidity = solidity > 0.9
            checkAspectRatio = 0.5 <= aspectRatio <= 1.5

            if checkDimensions and checkSolidity and checkAspectRatio:
                squares.append(c)

    return squares

def text(img, preprocess):
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    if preprocess == "thresh":
    	img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]
    elif preprocess == "blur":
    	img = cv2.medianBlur(img, 3)

    filename = "{}.png".format(os.getpid())
    cv2.imwrite(filename, img)

    text = pytesseract.image_to_string(Image.open(filename))
    os.remove(filename)
    return(text)
\end{lstlisting}

\subsection{Conclusions and Further Work}
Currectly, the program suffers from an issue where it cannot detect shapes within other shapes, as it relies on defining shapes relative to the background. This is an important capability, as looking for concentric squares will likely be the best way to detect the target. More work is neeeded to find a solution for this, and to further adapt the program to search for our target specifically.

\section{Overall Conclusion and Remaining Work}
The simulation can be improved further, but for now seems to indicate that our concept is viable. Of the software that will go on Pete, PX4 communication over MAVLink is complete, computer vision is a work in progress, and communication with a base station is yet to be started.

Once the control software is complete, it is hoped to create a new simulation using Gazebo. Gazebo is an advanced physics simulator for robots, and crucially can integrate with the PX4 SITL simulation. Such a simulation would be the most accurate way of determing the validity of both the design concept and control software.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BIBLIOGRAPHY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thebibliography}{11}

    \bibitem{IMechE_about_uas}
        IMechE. About UAS Challenge - IMechE [Internet]. [Accessed 20 December 2017]; Availible from: \url{https://www.imeche.org/events/challenges/uas-challenge/about-uas-challenge}.

    \bibitem{dronekit}
        3D Robotics. DroneKit-Python Documentation [Internet]. Updated 21 April 2017. [Accessed 20 December 2017]; Available from: \url{http://python.dronekit.io}.

    \bibitem{PX4_user_guide}
        DroneCode. PX4 Autopilot User Guide [Internet]. Updated 20 December 2017. [Last accessed 20 December 2017]; Availible from: \url{https://docs.px4.io/en/}.

    \bibitem{PX4_dev_guide}
        DroneCode. PX4 Development Guide [Internet]. Updated 15 December 2017. [Last accessed 20 December 2017]; Availible from: \url{https://dev.px4.io/en/}.

    \bibitem{IMechE_rules}
        Institution of Mechanical Engineers. University UAS Challenge 2018 Competition Rules [Internet]. Issue 7.1. [Accessed 27 December 2017]; Available from: \url{https://www.imeche.org/docs/default-source/1-oscar/uas-challenge/uas-challenge--competition-rules.pdf?sfvrsn=2}.

\end{thebibliography}

\begin{quote}
    \emph{I, Eugene Valetsky, confirm that the work presented in this report is my own. Where information has been derived from other sources, I confirm that this has been indicated in the report.}
\end{quote}


\end{document}
